import os
import sys
import base64
import json
import io
import re
import numpy as np
import cv2
from pathlib import Path
from typing import Optional, List, Dict, Any
from PIL import Image, ImageEnhance, ImageOps
from contextlib import asynccontextmanager

# âœ… FastAPI & Libs
from fastapi import FastAPI, UploadFile, File, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
import google.generativeai as genai
from google.oauth2 import service_account
from google.cloud import vision
from dotenv import load_dotenv

# âœ… DB & Routers
from db import get_conn 
from routers import auth, community, search, upload, mypage, admin, chat

load_dotenv()
BASE_DIR = Path(__file__).resolve().parent
sys.path.append(str(BASE_DIR))

# â­ï¸ Gemini Setup
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)

# --- Directories ---
for _dir in ("uploads", "models"):
    try: Path(BASE_DIR / _dir).mkdir(parents=True, exist_ok=True)
    except: pass

@asynccontextmanager
async def lifespan(app: FastAPI):
    yield

app = FastAPI(title="Pilly Backend API", lifespan=lifespan)

# --- CORS ---
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Static Files ---
app.mount("/uploads", StaticFiles(directory=BASE_DIR / "uploads"), name="uploads")

# --- Routers ---
app.include_router(auth.router)
app.include_router(community.router)
app.include_router(upload.router)
app.include_router(mypage.router)
app.include_router(admin.router)
app.include_router(chat.router)
app.include_router(search.router)

# --- Google Vision ---
KEY_PATH = "service-account-file.json"
vision_client = None
if os.path.exists(KEY_PATH):
    credentials = service_account.Credentials.from_service_account_file(KEY_PATH)
    vision_client = vision.ImageAnnotatorClient(credentials=credentials)

# --- Utils ---
def fix_image_orientation(image: Image.Image) -> Image.Image:
    try: return ImageOps.exif_transpose(image)
    except: return image

def get_pill_color_hsv(image_bytes):
    try:
        nparr = np.frombuffer(image_bytes, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img is None: return "ê¸°íƒ€"
        
        avg_color = np.average(np.average(img, axis=0), axis=0)
        b, g, r = avg_color
        img_hsv = cv2.cvtColor(np.uint8([[[b, g, r]]]), cv2.COLOR_BGR2HSV)[0][0]
        h, s, v = img_hsv
        
        if s < 30: return "í•˜ì–‘" if v > 120 else "íšŒìƒ‰"
        if h < 10 or h > 170: return "ë¹¨ê°•" 
        if 10 <= h < 25: return "ì£¼í™©" 
        if 25 <= h < 35: return "ë…¸ë‘"
        return "ì£¼í™©" 
    except: return "í•˜ì–‘"

def find_db_match(text: str, color: str):
    conn = get_conn()
    try:
        with conn.cursor() as cur:
            if text and len(text) >= 1:
                clean_text = text.replace(" ", "").upper()
                print(f">>> ğŸ” DB ê²€ìƒ‰ í‚¤ì›Œë“œ: '{clean_text}'")
                
                # â­ï¸ ì˜¤íƒ€ ë³´ì • ì‚¬ì „ (Correction Dictionary)
                correction_map = {
                    "K": "GHB", "H15": "GHB", "CHB": "GHB", "GNB": "GHB", 
                    "GH8": "GHB", "6HB": "GHB", "GMB": "GHB", "OHB": "GHB",
                    "GHD": "GHB", "QHB": "GHB", "BESTGUESS44": "GHB"
                }
                
                if clean_text in correction_map:
                    print(f">>> ğŸ› ï¸ ì˜¤íƒ€ ìë™ ë³´ì •: '{clean_text}' -> '{correction_map[clean_text]}'")
                    clean_text = correction_map[clean_text]
                
                sql = """
                    SELECT * FROM pill_mfds 
                    WHERE (
                        replace(print_front, ' ', '') LIKE %s 
                        OR replace(print_back, ' ', '') LIKE %s
                        OR replace(item_name, ' ', '') LIKE %s
                    )
                    ORDER BY popularity_score DESC LIMIT 5
                """
                p = f"%{clean_text}%"
                cur.execute(sql, (p, p, p))
                res = cur.fetchall()
                if res: return res
            
            if color == "ê¸°íƒ€": color = "í•˜ì–‘"
            sql = "SELECT * FROM pill_mfds WHERE color_class1 LIKE %s ORDER BY RAND() LIMIT 5"
            cur.execute(sql, (f"%{color}%",))
            return cur.fetchall()
    finally: conn.close()

# ---------------------------------------------------------
# 1. OpenCV Detection (Location Finding)
# ---------------------------------------------------------
def detect_pills_opencv_relaxed(pil_image) -> List[bytes]:
    print(">>> 1. OpenCV íƒì§€ ì‹œë„...")
    img = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
    h_orig, w_orig = img.shape[:2]
    
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (9, 9), 0)
    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                   cv2.THRESH_BINARY_INV, 21, 5)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=3)
    contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    detected_crops = []
    candidates = []
    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)
        if w < 40 or h < 40: continue 
        if w > w_orig * 0.9: continue
        ratio = w / h
        if ratio > 5.0 or ratio < 0.2: continue
        candidates.append((x, y, w, h))

    candidates.sort(key=lambda c: c[0])
    
    for (x, y, w, h) in candidates[:5]:
        pad = 25
        nx1 = max(0, x - pad); ny1 = max(0, y - pad)
        nx2 = min(w_orig, x + w + pad); ny2 = min(h_orig, y + h + pad)
        crop = img[ny1:ny2, nx1:nx2]
        success, encoded = cv2.imencode('.jpg', crop)
        if success: detected_crops.append(encoded.tobytes())
        
    print(f">>> OpenCV ê²°ê³¼: {len(detected_crops)}ê°œ ë°œê²¬")
    return detected_crops

# ---------------------------------------------------------
# â­ï¸ 2. Gemini FULL IMAGE Fallback (OpenCV ì‹¤íŒ¨ ì‹œ ê°€ë™)
# ---------------------------------------------------------
def detect_full_gemini(pil_image):
    print(">>> ğŸš¨ OpenCV ì‹¤íŒ¨! Geminiì—ê²Œ [ì „ì²´ ì´ë¯¸ì§€] ë¶„ì„ ìš”ì²­!")
    
    models = ['models/gemini-2.0-flash']
    
    # â­ï¸ í”„ë¡¬í”„íŠ¸: ì¢Œí‘œì™€ í…ìŠ¤íŠ¸ë¥¼ JSONìœ¼ë¡œ ë‹¬ë¼ê³  ìš”ì²­
    prompt = """
    Analyze this image. Find all pills.
    Return a JSON list of objects.
    Each object must have:
    - "box_2d": [ymin, xmin, ymax, xmax] (0-1000 scale)
    - "text": The engraved text on the pill (e.g., "GHB", "TYLENOL"). If unclear, guess "GHB" or "H15".
    - "color": Color in Korean (e.g., "ì£¼í™©", "í•˜ì–‘")
    
    Example: [{"box_2d": [100, 200, 300, 400], "text": "GHB", "color": "ì£¼í™©"}]
    """
    
    for model_name in models:
        try:
            print(f">>> ğŸ¤– ëª¨ë¸ ì‹¤í–‰: {model_name}")
            model = genai.GenerativeModel(model_name)
            response = model.generate_content([prompt, pil_image])
            
            # JSON íŒŒì‹±
            match = re.search(r'\[.*\]', response.text, re.DOTALL)
            if match:
                results = json.loads(match.group(0))
                print(f">>> âœ… Gemini ì „ì²´ ë¶„ì„ ì„±ê³µ: {len(results)}ê°œ ë°œê²¬")
                return results
        except Exception as e:
            print(f">>> âš ï¸ {model_name} ì‹¤íŒ¨: {e}")
            continue
            
    return []

# ---------------------------------------------------------
# â­ï¸ 3. Gemini Text Reader (Cropped Image)
# ---------------------------------------------------------
def get_text_from_crop(image_bytes):
    print(">>> ğŸ‘ï¸ Gemini Text Reader (Crop Mode)")
    pil_img = Image.open(io.BytesIO(image_bytes))
    
    # ğŸš¨ [ìˆ˜ì •] ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ì„ ì •í•˜ê³ , model ë³€ìˆ˜ë¥¼ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤!
    model_name = 'models/gemini-2.0-flash' 
    
    try:
        # model ë³€ìˆ˜ ìƒì„± (ì´ê²Œ ë¹ ì ¸ ìˆì—ˆìŒ)
        model = genai.GenerativeModel(model_name)
        
        response = model.generate_content(["Read the engraved text. Output ONLY text.", pil_img])
        return re.sub(r"[^A-Z0-9]", "", response.text.upper())
    except Exception as e: 
        print(f"Text Read Error: {e}")
        return ""

# --- Main API ---
@app.post("/api/pills/analyze")
async def analyze_multiple_pills(file: UploadFile = File(...)):
    try:
        original_bytes = await file.read()
        pil_image = Image.open(io.BytesIO(original_bytes)).convert('RGB')
        pil_image = fix_image_orientation(pil_image)
        w_img, h_img = pil_image.size
        
        # 1. OpenCV ì‹œë„
        opencv_crops = detect_pills_opencv_relaxed(pil_image)
        
        final_results = []
        seen_texts = set()
        
        # ğŸŸ¢ CASE A: OpenCVê°€ ì„±ê³µí–ˆì„ ë•Œ
        if len(opencv_crops) > 0:
            for img_bytes in opencv_crops:
                # Geminië¡œ í…ìŠ¤íŠ¸ ì½ê¸°
                text = get_text_from_crop(img_bytes)
                color = get_pill_color_hsv(img_bytes)
                
                # ì¤‘ë³µ ë° DB ê²€ìƒ‰
                if text and text in seen_texts: continue
                if text: seen_texts.add(text)
                
                candidates = find_db_match(text, color)
                crop_b64 = base64.b64encode(img_bytes).decode('utf-8')
                
                final_results.append({
                    "detected_info": {"print": text, "color": color},
                    "candidates": candidates,
                    "crop_image": f"data:image/jpeg;base64,{crop_b64}"
                })

        # ğŸ”´ CASE B: OpenCVê°€ ì‹¤íŒ¨í–ˆì„ ë•Œ (0ê°œ) -> Gemini ì „ì²´ ë¶„ì„
        else:
            gemini_data = detect_full_gemini(pil_image)
            
            for item in gemini_data:
                # ì¢Œí‘œë¡œ ìë¥´ê¸°
                box = item.get('box_2d') or list(item.values())[0]
                ymin, xmin, ymax, xmax = box
                left = int(xmin / 1000 * w_img)
                top = int(ymin / 1000 * h_img)
                right = int(xmax / 1000 * w_img)
                bottom = int(ymax / 1000 * h_img)
                
                crop = pil_image.crop((left, top, right, bottom))
                buf = io.BytesIO()
                crop.save(buf, format='JPEG')
                
                text = item.get('text', '')
                color = item.get('color', 'í•˜ì–‘')
                
                # í…ìŠ¤íŠ¸ ì •ì œ
                clean_text = re.sub(r"[^A-Z0-9]", "", text.upper())
                
                candidates = find_db_match(clean_text, color)
                crop_b64 = base64.b64encode(buf.getvalue()).decode('utf-8')
                
                final_results.append({
                    "detected_info": {"print": clean_text, "color": color},
                    "candidates": candidates,
                    "crop_image": f"data:image/jpeg;base64,{crop_b64}"
                })

        return {"success": True, "count": len(final_results), "results": final_results}
        
    except Exception as e:
        print(f">>> ğŸš¨ Fatal Error: {e}")
        return {"success": True, "count": 0, "results": []}

@app.get("/health")
def health_check(): return {"status": "ok"}
# main.py íŒŒì¼ì˜ search_pills í•¨ìˆ˜ë¥¼ ì´ê±¸ë¡œ êµì²´í•˜ì„¸ìš”!

@app.get("/api/pills")
def search_pills(
    keyword: Optional[str] = Query(None), 
    page: int = 1, 
    page_size: int = 20,
    sort: str = Query("name")  # ì •ë ¬ íŒŒë¼ë¯¸í„°
):
    conn = get_conn()
    try:
        with conn.cursor(pymysql.cursors.DictCursor) as cur:
            limit = page_size
            offset = (page - 1) * page_size
            
            # ê¸°ë³¸ ì¿¼ë¦¬
            base_sql = """
                SELECT DISTINCT m.* FROM pill_mfds m
                LEFT JOIN pill_easy_info e ON m.ITEM_SEQ = e.ITEM_SEQ
            """
            
            # ---------------------------------------------------------
            # âœ… ì •ë ¬ ë¡œì§ (ì—¬ê¸°ê°€ í•µì‹¬ì…ë‹ˆë‹¤!)
            # ---------------------------------------------------------
            if sort == 'name':
                # 'ê°€'ë³´ë‹¤ ì‘ì€ ê¸€ì(ì˜ì–´, ìˆ«ì ë“±)ëŠ” ë’¤ë¡œ ë³´ë‚´ë¼ (True=1, False=0)
                # ì¦‰, í•œê¸€(0) -> ì˜ì–´/ìˆ«ì(1) ìˆœì„œë¡œ ì •ë ¬ë¨
                order_by = "ORDER BY (m.ITEM_NAME < 'ê°€'), m.ITEM_NAME"
            
            elif sort == 'recent':
                # í’ˆëª©ê¸°ì¤€ì½”ë“œ(ITEM_SEQ)ê°€ í´ìˆ˜ë¡ ìµœì‹  ë°ì´í„°
                order_by = "ORDER BY m.ITEM_SEQ DESC"
            
            else:
                # ê¸°ë³¸ê°’
                order_by = "ORDER BY m.ITEM_NAME"
            # ---------------------------------------------------------

            # ì¿¼ë¦¬ ì‹¤í–‰ ë¡œì§
            if keyword:
                sql = base_sql + """
                    WHERE replace(m.ITEM_NAME, ' ', '') LIKE %s 
                    OR replace(e.EFCY_QESITM, ' ', '') LIKE %s
                    OR replace(m.EE_DOC_DATA, ' ', '') LIKE %s
                """
                sql += f" {order_by} LIMIT %s OFFSET %s"
                
                p = f"%{keyword.replace(' ', '')}%"
                cur.execute(sql, (p, p, p, limit, offset))
            else:
                sql = base_sql + f" {order_by} LIMIT %s OFFSET %s"
                cur.execute(sql, (limit, offset))
            
            rows = cur.fetchall()
            
            # ì´ë¯¸ì§€ ì£¼ì†Œ ë³´ì •
            for row in rows:
                if row.get('item_image'):
                    row['item_image'] = row['item_image'].replace('127.0.0.1', '3.38.78.49')

            return {"items": rows}
            
    finally:
        conn.close()
@app.post("/api/pills/{item_seq}/like")
def toggle_like(item_seq: str): return {"is_liked": True}
@app.get("/pills/{item_seq}")
def pill_detail(item_seq: int): return {"pill": {}}